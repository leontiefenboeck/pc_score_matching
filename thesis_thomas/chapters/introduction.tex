\chapter{Introduction}
\label{cha:introduction}

Side-channel attacks (SCAs) allow attackers to learn about secret material used in a cryptographic computation by observing implementation artifacts, such as timing information \cite{timing_kocher}, electromagnetic leaks \cite{em_gandolfi}, and power consumption \cite{dpa_kocher}. This auxiliary information is commonly called \textit{leakage}.
Most contemporary attacks use these leakages to reason about the state of intermediate values in an algorithm in a probabilistic manner, i.e., they output probability mass functions over possible states of intermediate variables. For example, given information about the power consumption of a device that performed encryption using the \textit{Advanced Encryption Standard} (AES), an attacker can use existing methods such as \textit{Template Attacks} \cite{template_attacks} to produce probability distributions that capture beliefs of the states of particular variables used in the AES, given the leakage (e.g., over individual bytes of the intermediate variables). Given these distributions and the knowledge of the software implementation of the algorithm, the goal of the attacker is to infer the posterior distribution of the secret key. While probability theory offers rigorous operations on how to perform this inference task (such as marginalization, conditioning, Bayes' rule, and maximum a posteriori), the high time of a na\"ive computation usually makes it infeasible for practical attacks. As a remedy, state-of-the-art attacks perform \textit{approximate} probabilistic inference: For example, \textit{Soft Analytical Side-Channel Attacks} (SASCAs) \cite{sasca} leverage loopy belief propagation, a method for approximate probabilistic inference that neither guarantees accurate estimates nor assures convergence and has limited theoretical underpinnings \cite{bp}.

Meanwhile, advancements in the fields of knowledge compilation and tractable probabilistic modeling have given rise to methods that can effectively combine both symbolic knowledge (the software implementation of the algorithm under attack) and probabilistic modeling (mass functions over states of variables) within a structure called a \textit{Probabilistic Circuit} (PC) \cite{sdd, psdd, dynamic_min_choi}. PCs can encode expressive probability distributions and, with certain structural constraints, are able to answer inference queries such as marginalization and maximum a posteriori queries in linear time in the size of the circuit \cite{psdd}.

In this work, we primarily ask two questions: Using a real-world dataset of power traces, can (1) we perform \textit{exact} probabilistic inference with the help of PCs, and if so, (2) does this improve the effectiveness of the side-channel attack when compared to approximate methods like SASCA?

% contributions: what are the main findings?
In a nutshell, we find that we can utilize PCs to tractably perform exact inference using sparse approximations of the probability mass functions of intermediate variables (under some \emph{low entropy} assumptions) and show that this method substantially outperforms state-of-the-art approaches that use loopy belief propagation while empirically demonstrating competitive runtimes.
Furthermore, we show that, if the distributions of intermediate variables are on the scope of individual \emph{bits}, PCs are able to tractably perform exact inference --- even \emph{without} approximation techniques. 

While not being the central focus of this work, we also discuss approaches that combine \emph{Deep Learning} based side-channel attacks with our proposed inference pipeline and show interesting connections to the field of \textit{neuro-symbolic learning}.

Throughout most of this work, we will slightly abuse the probability theoretic notation for conciseness and will mostly not differentiate between variables and the values they can take on. For example, instead of writing $p(X = x)$ to denote the probability that random variable $X$ assumes the value $x$, we simply write $p(x)$ where the random variable follows from the context in order to keep the notation uncluttered. 