\chapter{Abstract}

Probabilistic Circuits (PCs) have shown to be a promising approach to probabilistic modelling, due to their many 
effiecient and exact inference opportunities while still being complex enough to model arbitrary distibutions. 
However they still are difficult to train and lack in results compared to other state of the
art approaches in probabilistic modelling, especially with large high dimensional datasets. 
(Researchers fear that during the gradient based Maximum Likelihood optimization the algorithm gets stuck in local 
minima.) 
In this thesis I try to experimentally see if by using other learning objectives, namely sliced score matching, which 
recently gained prominence in learning energy based models (EBMs), we can work around these issues and achieve better results 
with PCs. 
I do this by training PCs using different algorithms on 2D and also high dimensional image data and comparing
results. 